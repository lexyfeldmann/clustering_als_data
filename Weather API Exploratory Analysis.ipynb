{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0e2ea7",
   "metadata": {},
   "source": [
    "## Lexy Feldmann<br>Using Weather API EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a910af8",
   "metadata": {},
   "source": [
    "### Set up the API data using documentation from the Weather API website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48278182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries (everything but pandas taken from the website)\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53daa7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error (all taken from the website)\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Store the API URL in a variable to use later\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc218cf",
   "metadata": {},
   "source": [
    "### Grab dataframe from the last project milestone that was formed through HTML data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f302d072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.546245</td>\n",
       "      <td>1.601554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>23.424076</td>\n",
       "      <td>53.847818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>17.060816</td>\n",
       "      <td>-61.796428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>18.220554</td>\n",
       "      <td>-63.068615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.153332</td>\n",
       "      <td>20.168331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>40.069099</td>\n",
       "      <td>45.038189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Netherlands Antilles</td>\n",
       "      <td>12.226079</td>\n",
       "      <td>-69.060087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.202692</td>\n",
       "      <td>17.873887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>-75.250973</td>\n",
       "      <td>-0.071389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index               Country    Latitude   Longitude\n",
       "0     1               Andorra   42.546245    1.601554\n",
       "1     2  United Arab Emirates   23.424076   53.847818\n",
       "2     3           Afghanistan    33.93911   67.709953\n",
       "3     4   Antigua and Barbuda   17.060816  -61.796428\n",
       "4     5              Anguilla   18.220554  -63.068615\n",
       "5     6               Albania   41.153332   20.168331\n",
       "6     7               Armenia   40.069099   45.038189\n",
       "7     8  Netherlands Antilles   12.226079  -69.060087\n",
       "8     9                Angola  -11.202692   17.873887\n",
       "9    10            Antarctica  -75.250973   -0.071389"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the countries_df dateframe from the Project - 3 Milestone file\n",
    "%store -r countries_df\n",
    "\n",
    "# Print the first ten rows of the dataframe to make sure it is there for use\n",
    "countries_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6665d7",
   "metadata": {},
   "source": [
    "### Function given to users from the weather API website. It shows how to handle daily data. I modified it so that I am only returning one row per country (get the average of all weather across 365 days) so that it is returned yearly for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb8e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_daily(response, country, latitude, longitude):\n",
    "    # Create a Daily object from the API response\n",
    "    daily = response.Daily()\n",
    "\n",
    "    # Grab the temperature, precipitation, and sunshine duration and store them in their respective variables\n",
    "    daily_temperature_2m_mean = daily.Variables(0).ValuesAsNumpy()\n",
    "    daily_precipitation_sum = daily.Variables(1).ValuesAsNumpy()\n",
    "    daily_sunshine_duration = daily.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "    # Create a dictionary for the date and data to grab (taken from the API website)\n",
    "    daily_data = {\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "            inclusive=\"left\"\n",
    "        ),\n",
    "        \"Average Temperature (째F)\": daily_temperature_2m_mean,\n",
    "        \"Average Precipitation (in.)\": daily_precipitation_sum,\n",
    "        \"Average Sunshine Duration (hrs)\": daily_sunshine_duration / 3600  # Convert seconds to hours\n",
    "    }\n",
    "\n",
    "    # Create a dataframe using the daily_data dictionary\n",
    "    daily_dataframe = pd.DataFrame(data=daily_data)\n",
    "\n",
    "    # Calculate the average of all temperatures, precipitations, and sunshine durations\n",
    "    average_temperature = daily_dataframe[\"Average Temperature (째F)\"].mean()\n",
    "    average_precipitation = daily_dataframe[\"Average Precipitation (in.)\"].mean()\n",
    "    average_sunshine = daily_dataframe[\"Average Sunshine Duration (hrs)\"].mean()\n",
    "\n",
    "    # Create a dictionary for the yearly average of temperature, precipitation, and sunshine duration for each country\n",
    "    average_data = {\n",
    "        \"Country\": [country],\n",
    "        \"Latitude\": [latitude],\n",
    "        \"Longitude\": [longitude],\n",
    "        \"Average Temperature (째F)\": [average_temperature],\n",
    "        \"Average Precipitation (in.)\": [average_precipitation],\n",
    "        \"Average Sunshine Duration (hrs)\": [average_sunshine]\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame with the yearly data\n",
    "    average_dataframe = pd.DataFrame(data=average_data)\n",
    "\n",
    "    # Return the yearly dataframe\n",
    "    return average_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034238f2",
   "metadata": {},
   "source": [
    "### 1. Create a dataframe, using a function, that utilizes inputted dictionary parameters and calls on the process_daily() function in order to properly grab 365 days worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95958cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a dictionary of parameters for the API to sift through, that then spits out the specified weather data\n",
    "def make_df(input_params):\n",
    "    \n",
    "    # Creates an empty dataframe with the specified columns\n",
    "    final_df = pd.DataFrame(columns=['Country', 'Latitude', 'Longitude', 'Average Temperature (째F)',\n",
    "                                     'Average Precipitation (in.)', 'Average Sunshine Duration (hrs)'])\n",
    "    \n",
    "    # Initialize an empty list to store DataFrames for concatenation\n",
    "    dfs_to_concat = []\n",
    "    \n",
    "    # Loop over countries_df to gather latitude and longitude for each location\n",
    "    for index, row in countries_df.iterrows():\n",
    "        country = row['Country']\n",
    "        latitude = row['Latitude']\n",
    "        longitude = row['Longitude']\n",
    "    \n",
    "        # Update input_params (to go into the API) with latitude and longitude from countries_df\n",
    "        input_params['latitude'] = latitude\n",
    "        input_params['longitude'] = longitude\n",
    "\n",
    "        # Retrieve weather data from the Open-Meteo API for the current location\n",
    "        responses = openmeteo.weather_api(url, params=input_params)\n",
    "    \n",
    "        # Process each response in the list\n",
    "        for response in responses:\n",
    "            \n",
    "            # Process the response and get the DataFrame using the process_daily function (gives one row for each country)\n",
    "            processed_df = process_daily(response, country, latitude, longitude)\n",
    "            \n",
    "            # Add country, latitude, and longitude to the processed DataFrame and set to the values from countries_df\n",
    "            processed_df['Country'] = country\n",
    "            processed_df['Latitude'] = latitude\n",
    "            processed_df['Longitude'] = longitude\n",
    "            \n",
    "            # Append the processed DataFrame to the list\n",
    "            dfs_to_concat.append(processed_df)\n",
    "        \n",
    "    # Concatenate all DataFrames in the list to one large dataframe for all countries (for that year)\n",
    "    final_df = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "    \n",
    "    # Return all countries for the current year\n",
    "    return final_df.head(244)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d32684",
   "metadata": {},
   "source": [
    "### 2. Add a year column to each dataset to be able to distinguish yearly weather changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfa6dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenMeteoRequestsError",
     "evalue": "{'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenMeteoRequestsError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21832\\2418598214.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Pass in the parameters into the make_df function and store it in a variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mweather_2015\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_2015\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Add a column for the year 2015\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21832\\1571735344.py\u001b[0m in \u001b[0;36mmake_df\u001b[1;34m(input_params)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Retrieve weather data from the Open-Meteo API for the current location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mresponses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenmeteo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweather_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Process each response in the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openmeteo_requests\\Client.py\u001b[0m in \u001b[0;36mweather_api\u001b[1;34m(self, url, params, method)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mweather_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"GET\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWeatherApiResponse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;34m\"\"\"Get and decode as weather api\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWeatherApiResponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openmeteo_requests\\Client.py\u001b[0m in \u001b[0;36m_get\u001b[1;34m(self, cls, url, params, method)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m429\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mresponse_body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOpenMeteoRequestsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOpenMeteoRequestsError\u001b[0m: {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}"
     ]
    }
   ],
   "source": [
    "# Specify the parameters and dates for the 2015 data in a dictionary format to pass into the make_df function\n",
    "params_2015 = {\n",
    "    \"start_date\": \"2015-01-01\",\n",
    "    \"end_date\": \"2015-12-31\",\n",
    "    \"daily\": \"temperature_2m_mean,precipitation_sum,sunshine_duration\",\n",
    "    \"temperature_unit\": \"fahrenheit\",\n",
    "    \"precipitation_unit\": \"inch\"\n",
    "}\n",
    "\n",
    "# Pass in the parameters into the make_df function and store it in a variable\n",
    "weather_2015 = make_df(params_2015)\n",
    "\n",
    "# Add a column for the year 2015\n",
    "weather_2015['Year'] = 2015\n",
    "\n",
    "# Print the first ten rows to check that it worked\n",
    "weather_2015.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters and dates for the 2016 data in a dictionary format to pass into the make_df function\n",
    "params_2016 = {\n",
    "    \"start_date\": \"2016-01-01\",\n",
    "    \"end_date\": \"2016-12-31\",\n",
    "    \"daily\": \"temperature_2m_mean,precipitation_sum,sunshine_duration\",\n",
    "    \"temperature_unit\": \"fahrenheit\",\n",
    "    \"precipitation_unit\": \"inch\"\n",
    "}\n",
    "\n",
    "# Pass in the parameters into the make_df function and store it in a variable\n",
    "weather_2016 = make_df(params_2016)\n",
    "\n",
    "# Add a column for the year 2016\n",
    "weather_2016['Year'] = 2016\n",
    "\n",
    "# Print the first ten rows to check that it worked\n",
    "weather_2016.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7764b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters and dates for the 2017 data in a dictionary format to pass into the make_df function\n",
    "params_2017 = {\n",
    "    \"start_date\": \"2017-01-01\",\n",
    "    \"end_date\": \"2017-12-31\",\n",
    "    \"daily\": \"temperature_2m_mean,precipitation_sum,sunshine_duration\",\n",
    "    \"temperature_unit\": \"fahrenheit\",\n",
    "    \"precipitation_unit\": \"inch\"\n",
    "}\n",
    "\n",
    "# Pass in the parameters into the make_df function and store it in a variable\n",
    "weather_2017 = make_df(params_2017)\n",
    "\n",
    "# Add a column for the year 2017\n",
    "weather_2017['Year'] = 2017\n",
    "\n",
    "# Print the first ten rows to check that it worked\n",
    "weather_2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters and dates for the 2018 data in a dictionary format to pass into the make_df function\n",
    "params_2018 = {\n",
    "    \"start_date\": \"2018-01-01\",\n",
    "    \"end_date\": \"2018-12-31\",\n",
    "    \"daily\": \"temperature_2m_mean,precipitation_sum,sunshine_duration\",\n",
    "    \"temperature_unit\": \"fahrenheit\",\n",
    "    \"precipitation_unit\": \"inch\"\n",
    "}\n",
    "\n",
    "# Pass in the parameters into the make_df function and store it in a variable\n",
    "weather_2018 = make_df(params_2018)\n",
    "\n",
    "# Add a column for the year 2018\n",
    "weather_2018['Year'] = 2018\n",
    "\n",
    "# Print the first ten rows to check that it worked\n",
    "weather_2018.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8066ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters and dates for the 2019 data in a dictionary format to pass into the make_df function\n",
    "params_2019 = {\n",
    "    \"start_date\": \"2019-01-01\",\n",
    "    \"end_date\": \"2019-12-31\",\n",
    "    \"daily\": \"temperature_2m_mean,precipitation_sum,sunshine_duration\",\n",
    "    \"temperature_unit\": \"fahrenheit\",\n",
    "    \"precipitation_unit\": \"inch\"\n",
    "}\n",
    "\n",
    "# Pass in the parameters into the make_df function and store it in a variable\n",
    "weather_2019 = make_df(params_2019)\n",
    "\n",
    "# Add a column for the year 2019\n",
    "weather_2019['Year'] = 2019\n",
    "\n",
    "# Print the first ten rows to check that it worked\n",
    "weather_2019.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93271156",
   "metadata": {},
   "source": [
    "### 3. Merge yearly dataframes into one large dataset (2015 - 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames (merge them all together)\n",
    "all_weather = pd.concat([weather_2015, weather_2016, weather_2017, weather_2018, weather_2019], ignore_index=True)\n",
    "\n",
    "# Verify the merge worked!\n",
    "all_weather.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a716b1",
   "metadata": {},
   "source": [
    "### 4. Remove unnecessary columns (no longer need latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the latitude and longitude, they were only need to map on Country to the weather data\n",
    "yearly_country_weather = all_weather.drop(columns=['Latitude', 'Longitude'])\n",
    "\n",
    "# Print to verify that the columns were dropped\n",
    "yearly_country_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fc599",
   "metadata": {},
   "source": [
    "### 5. Sort the dataframe by country and year (ascending) to better see yearly weather changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display rows to show ALL rows when printed\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Sort the weather data by the 'Country' and 'Year' columns in ascending order and print the dataframe\n",
    "yearly_country_weather.sort_values(by=['Country', 'Year'], ascending=[True, True])\n",
    "\n",
    "# Store the dataframe for later use\n",
    "%store yearly_country_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a09452",
   "metadata": {},
   "source": [
    "### Ethical Implications of My Data Wrangling Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b96989",
   "metadata": {},
   "source": [
    "The changes that were made to the data included creating a dataframe by extracting daily data and turning it into yearly data, adding a Year column to each yearly dataset, merging all yearly datasets together (now have weather data for each country in countries_df from 2015-2019), removing unnecessary columns from the merged dataset, and reordering the dataset to be in a more readable format. There are no legal or regulatory guidelines for my data or project topic. All data is public and none of it is sensitive. With transforming API data, you run the risk of not correctly calling on each piece of data. I checked to make sure I had handled this properly by manually inputting some of the latitudes and longitudes in the website for the specified dates, to see if it returned the same daily data that I had gotten before grabbing the average of all days and turning it into yearly data. I made no assumptions when cleaning the data, the only thing that MAY be considered an assumption is picking which daily data I deemed can increase or reduce happiness from the Weather API (average temperature, precipitation sum, sunshine duration). My data source is found on https://open-meteo.com/en/docs/historical-weather-api#hourly=&daily=temperature_2m_mean&temperature_unit=fahrenheit&wind_speed_unit=mph&precipitation_unit=inch, which is an entirely trusted source. It was acquired in an ethical way, as the site allows for easy access to the API (gives you example code on how to do so). I would mitigate the ethical implications by making sure I transformed my data efficiently and effectively - making sure all steps are accounted for and no transformations were messed up by either doing them in the wrong order or incorrectly. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
